{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38441087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694138c1",
   "metadata": {},
   "source": [
    "### Dataset 1 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5452c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_transform_1():\n",
    "    chars_folder_path = os.path.join('data','chars')\n",
    "    images_folder_path = os.path.join(chars_folder_path, 'images')\n",
    "    labels_path = os.path.join(chars_folder_path, 'labels.csv')\n",
    "    \n",
    "    dataset = pd.read_csv(labels_path)\n",
    "    images_arr = []\n",
    "    label_arr = dataset.iloc[:,1].values\n",
    "    i=0;\n",
    "    for image in dataset.iloc[:,0]:\n",
    "        image_path = os.path.join(images_folder_path, image[4:])\n",
    "        img = Image.open(image_path).convert('L')\n",
    "        \n",
    "        img = img.resize((28, 28), Image.Resampling.LANCZOS)\n",
    "        img_arr = np.array(img)\n",
    "        images_arr.append(img_arr)\n",
    "        \n",
    "        if(i%100 == 0):\n",
    "            print(f\"{i} image done\")\n",
    "        i+=1\n",
    "        \n",
    "    return images_arr, label_arr\n",
    "\n",
    "# x_chars, y_chars = load_data_transform_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "108c03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_chars[8], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07004329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv_1(x, y):\n",
    "    x = np.array(x)\n",
    "    x = x.reshape(-1, 784)\n",
    "    y = y.reshape(-1,1)\n",
    "    data = np.hstack((x, y))\n",
    "    dataFrame = pd.DataFrame(data)\n",
    "    dataFrame.to_csv('dataset_chars.csv',header = False)\n",
    "    \n",
    "# convert_to_csv_1(x_chars, y_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f64524",
   "metadata": {},
   "source": [
    "### Dataset 2 alphanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a200170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_transform_2():\n",
    "    alphanum_folder_path = os.path.join('data','alphanum')\n",
    "    img_arr = os.path.join(alphanum_folder_path, 'alphanum-hasy-data-X.npy')\n",
    "    img_label_arr = os.path.join(alphanum_folder_path, 'alphanum-hasy-data-y.npy')\n",
    "    symbol_map_path = os.path.join(alphanum_folder_path, 'symbols.csv')\n",
    "    \n",
    "    images = np.load(img_arr)\n",
    "    labels = np.load(img_label_arr).reshape(-1,1)\n",
    "    \n",
    "    symbol_map = pd.read_csv(symbol_map_path)\n",
    "    symbol_map_subset_1 = np.array(symbol_map.iloc[0:26, 0:2].values)\n",
    "    symbol_map_subset_2 = np.array(symbol_map.iloc[27:37, 0:2].values)\n",
    "    symbol_map_subset_3 = np.array(symbol_map.iloc[42:67, 0:2].values)\n",
    "    \n",
    "    symbol_map_subset = np.vstack((symbol_map_subset_1, symbol_map_subset_2, symbol_map_subset_3))\n",
    "    \n",
    "    img_arr = []\n",
    "    label_arr = []\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for label in labels:\n",
    "        if label in symbol_map_subset[:,0]:\n",
    "            im = Image.fromarray(images[i])\n",
    "            im = im.resize((28, 28), Image.Resampling.LANCZOS)\n",
    "            img_arr.append(np.array(im))\n",
    "            x = (np.where(symbol_map_subset[:,0]==label)[0][0])\n",
    "            label_arr.append(symbol_map_subset[x,1])\n",
    "            i+=1\n",
    "    \n",
    "    return img_arr, label_arr\n",
    "    \n",
    "# x_alphanum, y_alphanum = load_data_transform_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071b0646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x[225].reshape(28,28), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a50c0d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv_2(x, y):\n",
    "    x = np.array(x)\n",
    "    x = x.reshape(-1, 784)\n",
    "    y = np.array(y)\n",
    "    y = y.reshape(-1,1)\n",
    "    data = np.hstack((x, y))\n",
    "    dataFrame = pd.DataFrame(data)\n",
    "    dataFrame.to_csv('dataset_alphanum.csv',header = False)\n",
    "    \n",
    "# convert_to_csv_2(x_alphanum, y_alphanum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0620012e",
   "metadata": {},
   "source": [
    "### Dataset 3 EMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a92c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_transform_3():\n",
    "    chars_folder_path = os.path.join('data','emnist')\n",
    "    dataset_path = os.path.join(chars_folder_path, 'emnist-letters-train.csv')\n",
    "    \n",
    "    dataset = pd.read_csv(dataset_path, header=None)\n",
    "    labels = dataset.iloc[:,0:1].values\n",
    "    images = dataset.iloc[:, 1:].values\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# x_emnist, y_emnist = load_data_transform_3()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5a507cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv_3(x, y):\n",
    "    alphabet = ['','A','B', 'C','D','E','F','G','H','I','J','K','L','M',\n",
    "                'N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "    \n",
    "    y_new = []\n",
    "    i=0\n",
    "    for val in y:\n",
    "        y_new.append(alphabet[(int(val))])\n",
    "        i+=1\n",
    "        \n",
    "    y = np.array(y_new).reshape(-1,1)\n",
    "    data = np.hstack((x, y))\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('dataset_emnist.csv', header=False, index=False)\n",
    "    \n",
    "# convert_to_csv_3(x_emnist, y_emnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba322a",
   "metadata": {},
   "source": [
    "### Dataset 4 MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c4ec20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_transform_4():\n",
    "    mnist_folder_path = os.path.join('data','mnist')\n",
    "    mnist_data_path = os.path.join(mnist_folder_path, 'dataset.csv')\n",
    "    mnist_data = pd.read_csv(mnist_data_path)\n",
    "    y = mnist_data.iloc[:,0:1].values\n",
    "    x = mnist_data.iloc[:,1:].values\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "# x_mnist, y_mnist = load_data_transform_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af56a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv_4(x, y):\n",
    "    data = np.hstack((x, y))\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('dataset_mnist.csv', header=False, index=False)\n",
    "    \n",
    "# convert_to_csv_4(x_mnist, y_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f17145",
   "metadata": {},
   "source": [
    "### Dataset 5 A_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4abba846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_transform_5():\n",
    "    a_z_folder_path = os.path.join('data','a_z')\n",
    "    a_z_data_path = os.path.join(a_z_folder_path, 'A_Z Handwritten Data.csv')\n",
    "    a_z_data = pd.read_csv(a_z_data_path)\n",
    "\n",
    "    alphabet = ['A','B', 'C','D','E','F','G','H','I','J','K','L','M',\n",
    "                'N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "    \n",
    "    for i in range(a_z_data.shape[0]):\n",
    "         a_z_data.iloc[i, 0] = alphabet[int(a_z_data.iloc[i, 0])]\n",
    "    \n",
    "    a_z_data.to_csv('dataset_a_z.csv', index=False, header=False)\n",
    "\n",
    "load_data_transform_5()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da8ef2",
   "metadata": {},
   "source": [
    "### Dataset Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605dfd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_data():\n",
    "    mnist_data = pd.DataFrame(pd.read_csv('dataset_mnist.csv', header=None))\n",
    "    emnist_data = pd.DataFrame(pd.read_csv('dataset_emnist.csv', header=None))\n",
    "    alphanum_data = pd.DataFrame(pd.read_csv('dataset_alphanum.csv', header=None))\n",
    "    chars_data = pd.DataFrame(pd.read_csv('dataset_chars.csv', header=None))\n",
    "    mnist_data = pd.DataFrame(pd.DataFrame(mnist_data))\n",
    "    \n",
    "    dataset_final = pd.concat([mnist_data, emnist_data, alphanum_data, chars_data])\n",
    "    dataset_final.to_csv('dataset_final.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e70f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3194ee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_data_2():\n",
    "    mnist_data = pd.DataFrame(pd.read_csv('dataset_mnist.csv', header=None))\n",
    "    alphanum_data = pd.DataFrame(pd.read_csv('dataset_alphanum.csv', header=None))\n",
    "    chars_data = pd.DataFrame(pd.read_csv('dataset_chars.csv', header=None))\n",
    "    a_z_data = pd.DataFrame(pd.read_csv('dataset_a_z.csv', header=None))\n",
    "    mnist_data = pd.DataFrame(pd.DataFrame(mnist_data))\n",
    "    \n",
    "    dataset_final = pd.concat([mnist_data, alphanum_data, chars_data, a_z_data])\n",
    "    dataset_final.to_csv('dataset_final_2.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da5b47ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_all_data_2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
